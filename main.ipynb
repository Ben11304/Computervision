{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import function\n",
    "import utlis\n",
    "\n",
    "def main():\n",
    "    webCamFeed = True\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    cap.set(10,160)\n",
    "    og_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    og_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    print(f\"Input resolution: {og_w} x {og_h}\")\n",
    "    heightImg = 480\n",
    "    widthImg  = 640\n",
    "    h_rate=og_h/heightImg\n",
    "    w_rate=og_w/widthImg\n",
    "    utlis.initializeTrackbars()\n",
    "    count=0\n",
    "    while True:\n",
    "\n",
    "        if webCamFeed:success, img = cap.read()\n",
    "        ogImage=img.copy()\n",
    "        img = cv2.resize(img, (widthImg, heightImg))\n",
    "        imgBlank = np.zeros((heightImg,widthImg, 3), np.uint8)\n",
    "        config=utlis.valTrackbars() \n",
    "        imgGray, imgBlur, imgThreshold, imgDial,imgErode=function.preprocessing(img, config)\n",
    "        imgContours = img.copy()\n",
    "        imgBigContour = img.copy()\n",
    "        contours, hierarchy = cv2.findContours(imgErode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(imgContours, contours, -1, (255,183,178), 10)\n",
    "\n",
    "        biggest, maxArea = utlis.biggestContour(contours)\n",
    "        if biggest.size != 0:\n",
    "            biggest=utlis.reorder(biggest)\n",
    "            cv2.drawContours(imgBigContour, biggest, -1, (255,183,178), 20)\n",
    "            imgBigContour = utlis.drawRectangle(imgBigContour,biggest,2)\n",
    "            pts1 = np.float32(biggest)\n",
    "            pts2 = np.float32([[0, 0],[widthImg, 0], [0, heightImg],[widthImg, heightImg]])\n",
    "            matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "            imgWarpColored = cv2.warpPerspective(img, matrix, (widthImg, heightImg))\n",
    "            imgWarpColored = cv2.resize(imgWarpColored,(widthImg,heightImg))\n",
    "\n",
    "            Ogbiggest=utlis.Ogcontour(biggest,w_rate,h_rate)\n",
    "\n",
    "            ogImage=utlis.drawRectangle(ogImage,Ogbiggest,4)\n",
    "            cv2.drawContours(ogImage, Ogbiggest, -1, (0,0,255), 20)\n",
    "            imgresult,imgresult_=function.gen_results(ogImage,Ogbiggest)\n",
    "            imgWarpGray = cv2.cvtColor(imgWarpColored,cv2.COLOR_BGR2GRAY)\n",
    "            imgAdaptiveThre= cv2.adaptiveThreshold(imgWarpGray, 255, 1, 1, 7, 2)\n",
    "            imgAdaptiveThre = cv2.bitwise_not(imgAdaptiveThre)\n",
    "            imgAdaptiveThre=cv2.medianBlur(imgAdaptiveThre,3)\n",
    "\n",
    "            imageArray = ([imgBlur,imgThreshold,imgContours],\n",
    "                        [imgBigContour,imgWarpColored,imgAdaptiveThre])\n",
    "\n",
    "        else:\n",
    "\n",
    "            imageArray = ([imgBlur,imgThreshold,imgContours],\n",
    "                        [imgBlank, imgBlank, imgBlank])\n",
    "\n",
    "        # # LABELS FOR DISPLAY\n",
    "        # lables = [[\"Blur\",\"Gray\",\"Threshold\",\"Contours\"],\n",
    "        #           [\"Biggest Contour\",\"Warp Prespective\",\"Warp Gray\",\"Adaptive Threshold\"]]\n",
    "\n",
    "        stackedImage = utlis.stackImages(imageArray,0.75)\n",
    "        cv2.imshow(\"Result\",stackedImage)\n",
    "        cv2.imshow(\"original\", ogImage)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('b'):\n",
    "            cv2.imwrite(\"/Users/mac/Dev/Computer_Vision/Computer-Vision/ouput/vertical/myImage\"+str(count)+\".jpg\",imgresult)\n",
    "            cv2.imwrite(\"/Users/mac/Dev/Computer_Vision/Computer-Vision/ouput/horiziontal/myImage\"+str(count)+\".jpg\",imgresult_)\n",
    "            cv2.rectangle(stackedImage, ((int(stackedImage.shape[1] / 2) - 230), int(stackedImage.shape[0] / 2) + 50),\n",
    "                        (1100, 350), (255, 255, 255), cv2.FILLED)\n",
    "            cv2.putText(stackedImage, \"Đã lưu\", (int(stackedImage.shape[1] / 2) - 200, int(stackedImage.shape[0] / 2)),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 3, (0, 0, 0), 5, cv2.LINE_AA)\n",
    "            cv2.imshow('Result', stackedImage)\n",
    "            cv2.waitKey(300)\n",
    "            count += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 00:03:08.561 Python[6267:297530] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution: 1920 x 1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 00:03:09.231 Python[6267:297530] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m webCamFeed:success, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     26\u001b[0m     ogImage\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     27\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (widthImg, heightImg))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import utlis\n",
    "import function\n",
    "\n",
    "webCamFeed = True\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(10,160)\n",
    "\n",
    "og_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "og_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "print(f\"Resolution: {og_w} x {og_h}\")\n",
    "\n",
    "heightImg = 480\n",
    "widthImg  = 640\n",
    "h_rate=og_h/heightImg\n",
    "w_rate=og_w/widthImg\n",
    "\n",
    "utlis.initializeTrackbars()\n",
    "count=0\n",
    "\n",
    "while True:\n",
    "\n",
    "    if webCamFeed:success, img = cap.read()\n",
    "    ogImage=img.copy()\n",
    "    img = cv2.resize(img, (widthImg, heightImg))\n",
    "    imgBlank = np.zeros((heightImg,widthImg, 3), np.uint8)\n",
    "    config=utlis.valTrackbars() \n",
    "    imgGray, imgBlur, imgThreshold, imgDial,imgErode=function.preprocessing(img, config)\n",
    "    imgContours = img.copy()\n",
    "    imgBigContour = img.copy()\n",
    "    contours, hierarchy = cv2.findContours(imgErode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(imgContours, contours, -1, (255,0,0), 10)\n",
    "\n",
    "\n",
    "    biggest, maxArea = utlis.biggestContour(contours)\n",
    "    if biggest.size != 0:\n",
    "        biggest=utlis.reorder(biggest)\n",
    "        cv2.drawContours(imgBigContour, biggest, -1, (255,183,178), 20)\n",
    "        imgBigContour = utlis.drawRectangle(imgBigContour,biggest,2)\n",
    "        pts1 = np.float32(biggest)\n",
    "        pts2 = np.float32([[0, 0],[widthImg, 0], [0, heightImg],[widthImg, heightImg]])\n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        imgWarpColored = cv2.warpPerspective(img, matrix, (widthImg, heightImg))\n",
    "        imgWarpColored = cv2.resize(imgWarpColored,(widthImg,heightImg))\n",
    "\n",
    "        Ogbiggest=utlis.Ogcontour(biggest,w_rate,h_rate)\n",
    "\n",
    "        ogImage=utlis.drawRectangle(ogImage,Ogbiggest,8)\n",
    "        cv2.drawContours(ogImage, Ogbiggest, -1, (0,0,255), 20)\n",
    "        imgresult,imgresult_=function.gen_results(ogImage,Ogbiggest)\n",
    "\n",
    "        # resultH=297*3\n",
    "        # resultW=210*3\n",
    "        # pts1_=np.float32(Ogbiggest)\n",
    "        # pts2_ = np.float32([[0, 0],[resultW, 0], [0, resultH],[resultW, resultH]])\n",
    "        # matrix_ = cv2.getPerspectiveTransform(pts1_, pts2_)\n",
    "        # imgresult = cv2.warpPerspective(ogImage, matrix_, (resultW,resultH))\n",
    "        # imgresult= cv2.resize(imgresult,(resultW,resultH))\n",
    "        # imgresult = cv2.cvtColor(imgresult,cv2.COLOR_BGR2GRAY)\n",
    "        # imgresult=imgresult[20:imgresult.shape[0] - 20, 20:imgresult.shape[1] - 20]\n",
    "        # imgresult= cv2.adaptiveThreshold(imgresult, 255, 1, 1, 35, 2)\n",
    "        # # _,imgresult=cv2.threshold(imgresult, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        # imgresult = cv2.bitwise_not(imgresult)\n",
    "        # imgresult=cv2.medianBlur(imgresult,3)\n",
    "\n",
    "        # resultW=297*3\n",
    "        # resultH=210*3\n",
    "        # pts1_=np.float32(Ogbiggest)\n",
    "        # pts2_ = np.float32([[0, 0],[resultW, 0], [0, resultH],[resultW, resultH]])\n",
    "        # matrix_ = cv2.getPerspectiveTransform(pts1_, pts2_)\n",
    "        # imgresult_ = cv2.warpPerspective(ogImage, matrix_, (resultW,resultH))\n",
    "        # imgresult_= cv2.resize(imgresult_,(resultW,resultH))\n",
    "        # imgresult_ = cv2.cvtColor(imgresult_,cv2.COLOR_BGR2GRAY)\n",
    "        # imgresult_=imgresult_[20:imgresult_.shape[0] - 20, 20:imgresult_.shape[1] - 20]\n",
    "        # imgresult_= cv2.adaptiveThreshold(imgresult_, 255, 1, 1, 35, 2)\n",
    "        # # _,imgresult_=cv2.threshold(imgresult_, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        # imgresult_ = cv2.bitwise_not(imgresult_)\n",
    "        # imgresult_=cv2.medianBlur(imgresult_,3)\n",
    "\n",
    "        # APPLY ADAPTIVE THRESHOLD\n",
    "        imgWarpGray = cv2.cvtColor(imgWarpColored,cv2.COLOR_BGR2GRAY)\n",
    "        imgAdaptiveThre= cv2.adaptiveThreshold(imgWarpGray, 255, 1, 1, 7, 2)\n",
    "        imgAdaptiveThre = cv2.bitwise_not(imgAdaptiveThre)\n",
    "        imgAdaptiveThre=cv2.medianBlur(imgAdaptiveThre,3)\n",
    "\n",
    "        # Image Array for Display\n",
    "        imageArray = ([imgBlur,imgThreshold,imgContours],\n",
    "                      [imgBigContour,imgWarpColored,imgAdaptiveThre])\n",
    "\n",
    "    else:\n",
    "\n",
    "        imageArray = ([imgBlur,imgThreshold,imgContours],\n",
    "                      [imgBlank, imgBlank, imgBlank])\n",
    "\n",
    "\n",
    "    lables = [[\"Blured&Gray\",\"Threshold\",\"Contours\"],\n",
    "              [\"Biggest Contour\",\"Warp Prespective\",\"Adaptive Threshold\"]]\n",
    "\n",
    "    stackedImage = utlis.stackImages(imageArray,0.75,lables)\n",
    "    cv2.imshow(\"Result\",stackedImage)\n",
    "    cv2.imshow(\"original\", ogImage)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('b'):\n",
    "        cv2.imwrite(\"/Users/mac/Dev/Computer_Vision/Computer-Vision/ouput/vertical/myImage\"+str(count)+\".jpg\",imgresult)\n",
    "        cv2.imwrite(\"/Users/mac/Dev/Computer_Vision/Computer-Vision/ouput/horiziontal/myImage\"+str(count)+\".jpg\",imgresult_)\n",
    "        cv2.rectangle(stackedImage, ((int(stackedImage.shape[1] / 2) - 230), int(stackedImage.shape[0] / 2) + 50),\n",
    "                      (1100, 350), (255, 255, 255), cv2.FILLED)\n",
    "        cv2.putText(stackedImage, \"Đã lưu\", (int(stackedImage.shape[1] / 2) - 200, int(stackedImage.shape[0] / 2)),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 3, (0, 0, 0), 5, cv2.LINE_AA)\n",
    "        cv2.imshow('Result', stackedImage)\n",
    "        cv2.waitKey(300)\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/mac/Dev/Computer_Vision/Computer-Vision/My-project/function.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DocSanner",
   "language": "python",
   "name": "docscanner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
